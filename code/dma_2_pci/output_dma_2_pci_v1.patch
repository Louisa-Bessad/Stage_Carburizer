diff -u -p a/realtek/8139cp.c b/realtek/8139cp.c
--- a/realtek/8139cp.c
+++ b/realtek/8139cp.c
@@ -520,7 +520,7 @@ rx_status_loop:
 			goto rx_next;
 		}
 
-		new_mapping = dma_map_single(&cp->pdev->dev, new_skb->data, buflen,
+		new_mapping = pci_map_single(cp->pdev, new_skb->data, buflen,
 					 PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&cp->pdev->dev, new_mapping)) {
 			dev->stats.rx_dropped++;
@@ -759,7 +759,7 @@ static netdev_tx_t cp_start_xmit (struct
 		dma_addr_t mapping;
 
 		len = skb->len;
-		mapping = dma_map_single(&cp->pdev->dev, skb->data, len, PCI_DMA_TODEVICE);
+		mapping = pci_map_single(cp->pdev, skb->data, len, PCI_DMA_TODEVICE);
 		if (dma_mapping_error(&cp->pdev->dev, mapping))
 			goto out_dma_error;
 
@@ -798,7 +798,7 @@ static netdev_tx_t cp_start_xmit (struct
 		 */
 		first_eor = eor;
 		first_len = skb_headlen(skb);
-		first_mapping = dma_map_single(&cp->pdev->dev, skb->data,
+		first_mapping = pci_map_single(cp->pdev, skb->data,
 					       first_len, PCI_DMA_TODEVICE);
 		if (dma_mapping_error(&cp->pdev->dev, first_mapping))
 			goto out_dma_error;
@@ -813,7 +813,7 @@ static netdev_tx_t cp_start_xmit (struct
 			dma_addr_t mapping;
 
 			len = skb_frag_size(this_frag);
-			mapping = dma_map_single(&cp->pdev->dev,
+			mapping = pci_map_single(cp->pdev,
 						 skb_frag_address(this_frag),
 						 len, PCI_DMA_TODEVICE);
 			if (dma_mapping_error(&cp->pdev->dev, mapping)) {
@@ -1060,7 +1060,7 @@ static int cp_refill_rx(struct cp_privat
 		if (!skb)
 			goto err_out;
 
-		mapping = dma_map_single(&cp->pdev->dev, skb->data,
+		mapping = pci_map_single(cp->pdev, skb->data,
 					 cp->rx_buf_sz, PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&cp->pdev->dev, mapping)) {
 			kfree_skb(skb);
diff -u -p a/intel/ixgbevf/ixgbevf_main.c b/intel/ixgbevf/ixgbevf_main.c
--- a/intel/ixgbevf/ixgbevf_main.c
+++ b/intel/ixgbevf/ixgbevf_main.c
@@ -400,9 +400,9 @@ static void ixgbevf_alloc_rx_buffers(str
 			bi->skb = skb;
 		}
 		if (!bi->dma) {
-			bi->dma = dma_map_single(&pdev->dev, skb->data,
+			bi->dma = pci_map_single(pdev, skb->data,
 						 rx_ring->rx_buf_len,
-						 DMA_FROM_DEVICE);
+						 PCI_DMA_FROMDEVICE);
 		}
 		/* Refresh the desc even if buffer_addrs didn't change because
 		 * each write-back erases this info. */
@@ -2894,9 +2894,9 @@ static int ixgbevf_tx_map(struct ixgbevf
 
 		tx_buffer_info->length = size;
 		tx_buffer_info->mapped_as_page = false;
-		tx_buffer_info->dma = dma_map_single(&adapter->pdev->dev,
+		tx_buffer_info->dma = pci_map_single(adapter->pdev,
 						     skb->data + offset,
-						     size, DMA_TO_DEVICE);
+						     size, PCI_DMA_TODEVICE);
 		if (dma_mapping_error(&pdev->dev, tx_buffer_info->dma))
 			goto dma_error;
 		tx_buffer_info->time_stamp = jiffies;
diff -u -p a/intel/e1000/e1000_main.c b/intel/e1000/e1000_main.c
--- a/intel/e1000/e1000_main.c
+++ b/intel/e1000/e1000_main.c
@@ -2882,9 +2882,9 @@ static int e1000_tx_map(struct e1000_ada
 		/* set time_stamp *before* dma to help avoid a possible race */
 		buffer_info->time_stamp = jiffies;
 		buffer_info->mapped_as_page = false;
-		buffer_info->dma = dma_map_single(&pdev->dev,
+		buffer_info->dma = pci_map_single(pdev,
 						  skb->data + offset,
-						  size,	DMA_TO_DEVICE);
+						  size,	PCI_DMA_TODEVICE);
 		if (dma_mapping_error(&pdev->dev, buffer_info->dma))
 			goto dma_error;
 		buffer_info->next_to_watch = i;
@@ -4284,10 +4284,10 @@ static void e1000_alloc_rx_buffers(struc
 		buffer_info->skb = skb;
 		buffer_info->length = adapter->rx_buffer_len;
 map_skb:
-		buffer_info->dma = dma_map_single(&pdev->dev,
+		buffer_info->dma = pci_map_single(pdev,
 						  skb->data,
 						  buffer_info->length,
-						  DMA_FROM_DEVICE);
+						  PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&pdev->dev, buffer_info->dma)) {
 			dev_kfree_skb(skb);
 			buffer_info->skb = NULL;
diff -u -p a/intel/e1000/e1000_ethtool.c b/intel/e1000/e1000_ethtool.c
--- a/intel/e1000/e1000_ethtool.c
+++ b/intel/e1000/e1000_ethtool.c
@@ -1013,8 +1013,8 @@ static int e1000_setup_desc_rings(struct
 		txdr->buffer_info[i].skb = skb;
 		txdr->buffer_info[i].length = skb->len;
 		txdr->buffer_info[i].dma =
-			dma_map_single(&pdev->dev, skb->data, skb->len,
-				       DMA_TO_DEVICE);
+			pci_map_single(pdev, skb->data, skb->len,
+				       PCI_DMA_TODEVICE);
 		tx_desc->buffer_addr = cpu_to_le64(txdr->buffer_info[i].dma);
 		tx_desc->lower.data = cpu_to_le32(skb->len);
 		tx_desc->lower.data |= cpu_to_le32(E1000_TXD_CMD_EOP |
@@ -1070,8 +1070,9 @@ static int e1000_setup_desc_rings(struct
 		rxdr->buffer_info[i].skb = skb;
 		rxdr->buffer_info[i].length = E1000_RXBUFFER_2048;
 		rxdr->buffer_info[i].dma =
-			dma_map_single(&pdev->dev, skb->data,
-				       E1000_RXBUFFER_2048, DMA_FROM_DEVICE);
+			pci_map_single(pdev, skb->data,
+				       E1000_RXBUFFER_2048,
+				       PCI_DMA_FROMDEVICE);
 		rx_desc->buffer_addr = cpu_to_le64(rxdr->buffer_info[i].dma);
 		memset(skb->data, 0x00, skb->len);
 	}
diff -u -p a/intel/ixgbe/ixgbe_fcoe.c b/intel/ixgbe/ixgbe_fcoe.c
--- a/intel/ixgbe/ixgbe_fcoe.c
+++ b/intel/ixgbe/ixgbe_fcoe.c
@@ -614,10 +614,10 @@ void ixgbe_configure_fcoe(struct ixgbe_a
 		}
 
 		fcoe->extra_ddp_buffer_dma =
-			dma_map_single(&adapter->pdev->dev,
+			pci_map_single(adapter->pdev,
 				       fcoe->extra_ddp_buffer,
 				       IXGBE_FCBUFF_MIN,
-				       DMA_FROM_DEVICE);
+				       PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&adapter->pdev->dev,
 				      fcoe->extra_ddp_buffer_dma)) {
 			e_err(drv, "failed to map extra DDP buffer\n");
diff -u -p a/intel/ixgb/ixgb_main.c b/intel/ixgb/ixgb_main.c
--- a/intel/ixgb/ixgb_main.c
+++ b/intel/ixgb/ixgb_main.c
@@ -1365,9 +1365,9 @@ ixgb_tx_map(struct ixgb_adapter *adapter
 		WARN_ON(buffer_info->dma != 0);
 		buffer_info->time_stamp = jiffies;
 		buffer_info->mapped_as_page = false;
-		buffer_info->dma = dma_map_single(&pdev->dev,
+		buffer_info->dma = pci_map_single(pdev,
 						  skb->data + offset,
-						  size, DMA_TO_DEVICE);
+						  size, PCI_DMA_TODEVICE);
 		if (dma_mapping_error(&pdev->dev, buffer_info->dma))
 			goto dma_error;
 		buffer_info->next_to_watch = 0;
@@ -2164,10 +2164,10 @@ ixgb_alloc_rx_buffers(struct ixgb_adapte
 		buffer_info->skb = skb;
 		buffer_info->length = adapter->rx_buffer_len;
 map_skb:
-		buffer_info->dma = dma_map_single(&pdev->dev,
+		buffer_info->dma = pci_map_single(pdev,
 		                                  skb->data,
 		                                  adapter->rx_buffer_len,
-						  DMA_FROM_DEVICE);
+						  PCI_DMA_FROMDEVICE);
 
 		rx_desc = IXGB_RX_DESC(*rx_ring, i);
 		rx_desc->buff_addr = cpu_to_le64(buffer_info->dma);
diff -u -p a/intel/e1000e/netdev.c b/intel/e1000e/netdev.c
--- a/intel/e1000e/netdev.c
+++ b/intel/e1000e/netdev.c
@@ -639,9 +639,9 @@ static void e1000_alloc_rx_buffers(struc
 
 		buffer_info->skb = skb;
 map_skb:
-		buffer_info->dma = dma_map_single(&pdev->dev, skb->data,
+		buffer_info->dma = pci_map_single(pdev, skb->data,
 						  adapter->rx_buffer_len,
-						  DMA_FROM_DEVICE);
+						  PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&pdev->dev, buffer_info->dma)) {
 			dev_err(&pdev->dev, "Rx DMA map failed\n");
 			adapter->rx_dma_failed++;
@@ -740,9 +740,9 @@ static void e1000_alloc_rx_buffers_ps(st
 		}
 
 		buffer_info->skb = skb;
-		buffer_info->dma = dma_map_single(&pdev->dev, skb->data,
+		buffer_info->dma = pci_map_single(pdev, skb->data,
 						  adapter->rx_ps_bsize0,
-						  DMA_FROM_DEVICE);
+						  PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&pdev->dev, buffer_info->dma)) {
 			dev_err(&pdev->dev, "Rx DMA map failed\n");
 			adapter->rx_dma_failed++;
@@ -4676,9 +4676,9 @@ static int e1000_tx_map(struct e1000_ada
 		buffer_info->length = size;
 		buffer_info->time_stamp = jiffies;
 		buffer_info->next_to_watch = i;
-		buffer_info->dma = dma_map_single(&pdev->dev,
+		buffer_info->dma = pci_map_single(pdev,
 						  skb->data + offset,
-						  size, DMA_TO_DEVICE);
+						  size, PCI_DMA_TODEVICE);
 		buffer_info->mapped_as_page = false;
 		if (dma_mapping_error(&pdev->dev, buffer_info->dma))
 			goto dma_error;
diff -u -p a/intel/e1000e/ethtool.c b/intel/e1000e/ethtool.c
--- a/intel/e1000e/ethtool.c
+++ b/intel/e1000e/ethtool.c
@@ -1110,8 +1110,8 @@ static int e1000_setup_desc_rings(struct
 		tx_ring->buffer_info[i].skb = skb;
 		tx_ring->buffer_info[i].length = skb->len;
 		tx_ring->buffer_info[i].dma =
-			dma_map_single(&pdev->dev, skb->data, skb->len,
-				       DMA_TO_DEVICE);
+			pci_map_single(pdev, skb->data, skb->len,
+				       PCI_DMA_TODEVICE);
 		if (dma_mapping_error(&pdev->dev,
 				      tx_ring->buffer_info[i].dma)) {
 			ret_val = 4;
@@ -1175,8 +1175,8 @@ static int e1000_setup_desc_rings(struct
 		skb_reserve(skb, NET_IP_ALIGN);
 		rx_ring->buffer_info[i].skb = skb;
 		rx_ring->buffer_info[i].dma =
-			dma_map_single(&pdev->dev, skb->data, 2048,
-				       DMA_FROM_DEVICE);
+			pci_map_single(pdev, skb->data, 2048,
+				       PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&pdev->dev,
 				      rx_ring->buffer_info[i].dma)) {
 			ret_val = 8;
diff -u -p a/intel/igbvf/netdev.c b/intel/igbvf/netdev.c
--- a/intel/igbvf/netdev.c
+++ b/intel/igbvf/netdev.c
@@ -187,9 +187,9 @@ static void igbvf_alloc_rx_buffers(struc
 			}
 
 			buffer_info->skb = skb;
-			buffer_info->dma = dma_map_single(&pdev->dev, skb->data,
+			buffer_info->dma = pci_map_single(pdev, skb->data,
 			                                  bufsz,
-							  DMA_FROM_DEVICE);
+							  PCI_DMA_FROMDEVICE);
 		}
 		/* Refresh the desc even if buffer_addrs didn't change because
 		 * each write-back erases this info. */
@@ -2038,8 +2038,8 @@ static inline int igbvf_tx_map_adv(struc
 	buffer_info->time_stamp = jiffies;
 	buffer_info->next_to_watch = i;
 	buffer_info->mapped_as_page = false;
-	buffer_info->dma = dma_map_single(&pdev->dev, skb->data, len,
-					  DMA_TO_DEVICE);
+	buffer_info->dma = pci_map_single(pdev, skb->data, len,
+					  PCI_DMA_TODEVICE);
 	if (dma_mapping_error(&pdev->dev, buffer_info->dma))
 		goto dma_error;
 
diff -u -p a/brocade/bna/bnad.c b/brocade/bna/bnad.c
--- a/brocade/bna/bnad.c
+++ b/brocade/bna/bnad.c
@@ -379,9 +379,9 @@ bnad_alloc_n_post_rxbufs(struct bnad *bn
 			goto finishing;
 		}
 		unmap_array[unmap_prod].skb = skb;
-		dma_addr = dma_map_single(&bnad->pcidev->dev, skb->data,
+		dma_addr = pci_map_single(bnad->pcidev, skb->data,
 					  rcb->rxq->buffer_size,
-					  DMA_FROM_DEVICE);
+					  PCI_DMA_FROMDEVICE);
 		dma_unmap_addr_set(&unmap_array[unmap_prod], dma_addr,
 				   dma_addr);
 		BNA_SET_DMA_ADDR(dma_addr, &rxent->host_addr);
@@ -2730,8 +2730,8 @@ bnad_start_xmit(struct sk_buff *skb, str
 	unmap_q->unmap_array[unmap_prod].skb = skb;
 	len = skb_headlen(skb);
 	txqent->vector[0].length = htons(len);
-	dma_addr = dma_map_single(&bnad->pcidev->dev, skb->data,
-				  skb_headlen(skb), DMA_TO_DEVICE);
+	dma_addr = pci_map_single(bnad->pcidev, skb->data,
+				  skb_headlen(skb), PCI_DMA_TODEVICE);
 	dma_unmap_addr_set(&unmap_q->unmap_array[unmap_prod], dma_addr,
 			   dma_addr);
 
diff -u -p a/oki-semi/pch_gbe/pch_gbe_main.c b/oki-semi/pch_gbe/pch_gbe_main.c
--- a/oki-semi/pch_gbe/pch_gbe_main.c
+++ b/oki-semi/pch_gbe/pch_gbe_main.c
@@ -1044,9 +1044,9 @@ static void pch_gbe_tx_queue(struct pch_
 	       (skb->len - ETH_HLEN));
 	/*-- Set Buffer information --*/
 	buffer_info->length = tmp_skb->len;
-	buffer_info->dma = dma_map_single(&adapter->pdev->dev, tmp_skb->data,
+	buffer_info->dma = pci_map_single(adapter->pdev, tmp_skb->data,
 					  buffer_info->length,
-					  DMA_TO_DEVICE);
+					  PCI_DMA_TODEVICE);
 	if (dma_mapping_error(&adapter->pdev->dev, buffer_info->dma)) {
 		pr_err("TX DMA map failed\n");
 		buffer_info->dma = 0;
@@ -1275,10 +1275,10 @@ pch_gbe_alloc_rx_buffers(struct pch_gbe_
 		skb_reserve(skb, NET_IP_ALIGN);
 		buffer_info->skb = skb;
 
-		buffer_info->dma = dma_map_single(&pdev->dev,
+		buffer_info->dma = pci_map_single(pdev,
 						  buffer_info->rx_buffer,
 						  buffer_info->length,
-						  DMA_FROM_DEVICE);
+						  PCI_DMA_FROMDEVICE);
 		if (dma_mapping_error(&adapter->pdev->dev, buffer_info->dma)) {
 			dev_kfree_skb(skb);
 			buffer_info->skb = NULL;
diff -u -p a/dlink/sundance.c b/dlink/sundance.c
--- a/dlink/sundance.c
+++ b/dlink/sundance.c
@@ -1026,9 +1026,9 @@ static void init_ring(struct net_device
 			break;
 		skb->dev = dev;		/* Mark as being used by this device. */
 		skb_reserve(skb, 2);	/* 16 byte align the IP header. */
-		np->rx_ring[i].frag[0].addr = cpu_to_le32(
-			dma_map_single(&np->pci_dev->dev, skb->data,
-				np->rx_buf_sz, DMA_FROM_DEVICE));
+		np->rx_ring[i].frag[0].addr = cpu_to_le32(pci_map_single(np->pci_dev,
+							  skb->data,
+				np->rx_buf_sz, PCI_DMA_FROMDEVICE));
 		if (dma_mapping_error(&np->pci_dev->dev,
 					np->rx_ring[i].frag[0].addr)) {
 			dev_kfree_skb(skb);
@@ -1085,8 +1085,8 @@ start_tx (struct sk_buff *skb, struct ne
 
 	txdesc->next_desc = 0;
 	txdesc->status = cpu_to_le32 ((entry << 2) | DisableAlign);
-	txdesc->frag[0].addr = cpu_to_le32(dma_map_single(&np->pci_dev->dev,
-				skb->data, skb->len, DMA_TO_DEVICE));
+	txdesc->frag[0].addr = cpu_to_le32(pci_map_single(np->pci_dev,
+				skb->data, skb->len, PCI_DMA_TODEVICE));
 	if (dma_mapping_error(&np->pci_dev->dev,
 				txdesc->frag[0].addr))
 			goto drop_frame;
@@ -1417,9 +1417,9 @@ static void refill_rx (struct net_device
 				break;		/* Better luck next round. */
 			skb->dev = dev;		/* Mark as being used by this device. */
 			skb_reserve(skb, 2);	/* Align IP on 16 byte boundaries */
-			np->rx_ring[entry].frag[0].addr = cpu_to_le32(
-				dma_map_single(&np->pci_dev->dev, skb->data,
-					np->rx_buf_sz, DMA_FROM_DEVICE));
+			np->rx_ring[entry].frag[0].addr = cpu_to_le32(pci_map_single(np->pci_dev,
+								      skb->data,
+					np->rx_buf_sz, PCI_DMA_FROMDEVICE));
 			if (dma_mapping_error(&np->pci_dev->dev,
 				    np->rx_ring[entry].frag[0].addr)) {
 			    dev_kfree_skb_irq(skb);
